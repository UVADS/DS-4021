{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffcd19bb-da79-45fa-ac56-4ca6470d9eed",
   "metadata": {},
   "source": [
    "# ðŸ§ª LAB: Implement an autoencoder with `PyTorch`\n",
    "\n",
    "In this lab, you will implement and explore autoencoders using the MNIST dataset. The goal is to understand how autoencoders learn compressed representations of data, and how these representations compare with classical methods like PCA.\n",
    "\n",
    "**Collaboration Note**: This assignment is designed to support collaborative work. We encourage you to divide tasks among group members so that everyone can contribute meaningfully. Many components of the assignment can be approached in parallel or split logically across team members. Good coordination and thoughtful integration of your work will lead to a stronger final result.\n",
    "\n",
    "---\n",
    "\n",
    "In total, this lab assignment will be worth **100 points**.\n",
    "\n",
    "--- \n",
    "**Submission notes**:\n",
    "\n",
    "* Write down all group members' names, or at least the group name (if you have one and you previously provided it), in the first cell of the notebook.\n",
    "\n",
    "* Verify that the notebook runs as expected and that all required outputs are included.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aec1ee-1f98-4046-8abc-18bab21a915f",
   "metadata": {},
   "source": [
    "NAME(s) = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f69871-4218-4723-afb5-d10333180490",
   "metadata": {},
   "source": [
    "## 1. Theoretical Background Reflection (10 points)\n",
    "\n",
    "Read *Michelucci (2022)*: [An Introduction to Autoencoders](https://arxiv.org/abs/2201.03898) â€” focus on the following sections:  \n",
    "- 1.Introduction\n",
    "- 2.1, 2.2, and 2.3\n",
    "- Skim Section 3 on applications  \n",
    "\n",
    "Then answer briefly:\n",
    "\n",
    "1. What is the main idea behind an autoencoder?  \n",
    "2. What is the role of the bottleneck layer?  \n",
    "3. Discuss, in your own words, the applications of autoencoders mentioned in the paper.  \n",
    "4. What differences would you expect between an autoencoderâ€™s representation and that of PCA if applied as a dimensionality reduction technique?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27619d2b-c1fb-4d32-904d-c94acac83fe9",
   "metadata": {},
   "source": [
    "USE AS MANY MARKDOWN CELLS AS NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511c32d-b0f0-4096-83d1-9bc5a7f1b6c6",
   "metadata": {},
   "source": [
    "## 2. Prepare the Data (10 points)\n",
    "\n",
    "Given the below dataset:\n",
    "\n",
    "- Normalize **each** image (i.e., separately) so its values are between 0 and 1.\n",
    "- Visualize a few random digits to confirm everything worked as expected.\n",
    "- Split the dataset into training, validation and test sets (70%, 15% 15%).\n",
    "- Convert the splits into `PyTorch` `TensorDataset` objects and wrap them in `DataLoader`s with a batch size of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c98f2-99f7-4269-bb65-62267527da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml(\"mnist_784\", version=1, as_frame=False)\n",
    "X, y = mnist.data, mnist.target.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7998ad3e-3ee4-4261-a58d-1464e4da473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE AS MANY CELLS AS NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508c0516-17d2-4970-b303-7fd850db7c08",
   "metadata": {},
   "source": [
    "## 3. Autoencoder (50 points)\n",
    "\n",
    "In this section, you will build and train an **autoencoder** to reconstruct the provided data.\n",
    "\n",
    "Your model will include three layers in both the encoder and decoder:\n",
    "\n",
    "- **Encoder:** 784 â†’ 128 â†’ 64 â†’ 2 (the last layer is the **bottleneck**)  \n",
    "- **Decoder:** 2 â†’ 64 â†’ 128 â†’ 784  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e5ea4-93e2-4527-b166-9b4933367a76",
   "metadata": {},
   "source": [
    "### 3.1 Implementation (30 points)\n",
    "\n",
    "Follow the skeleton provided below and fill in the missing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69833245-f165-4796-b8b3-0aefb083194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ðŸ”¹ ENCODING PART: 784 -> 128 -> 64 -> 2\n",
    "        encoder_list = [\n",
    "            nn.Linear(784, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # TODO: Add steps to go from 128 to 64 \n",
    "            # (Linear â†’ BatchNorm â†’ ReLU â†’ Dropout(0.2))\n",
    "            \n",
    "            # TODO: Add steps to go from 64 to 2  \n",
    "            # (only Linear â†’ ReLU)\n",
    "        ]\n",
    "        # TODO: Replace the None value below with the module that stores the layers in 'encoder_list' for manual iteration in the forward pass\n",
    "        # Hint: we have covered this module in class\n",
    "        self.encoder_list = None\n",
    "        \n",
    "        # ðŸ”¹ DECODING PART: 2 -> 64 -> 128 -> 784\n",
    "        decoder_list = [\n",
    "            nn.Linear(2, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # TODO: Add steps to go from 64 to 128  \n",
    "            # (Linear â†’ BatchNorm â†’ ReLU â†’ Dropout(0.2))\n",
    "            \n",
    "            # TODO: Add steps to go from 128 to 784  \n",
    "            # (only Linear â†’ Sigmoid)\n",
    "        ]\n",
    "        # TODO: Replace the None value below with the module that stores the layers in 'decoder_list' for manual iteration in the forward pass\n",
    "        # Hint: we have covered this module in class\n",
    "        self.decoder_list = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # TODO: Replace the None value below for that after applying X -> encoder -> decoder\n",
    "        # Hint: You will probably need to iterate through the encoder_list and decoder_list\n",
    "        output = None\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df39c58d-127e-4101-a048-410870f0edcf",
   "metadata": {},
   "source": [
    "### 3.2 Training (15 points)\n",
    "\n",
    "Follow the skeleton provided below and fill in the missing parts to train your model. As you can see, training includes EarlyStopping, which I give you already for your convenience :-). After you have filled these missing parts, uncomment the provided piece of code with the function for training (`train_autoencoder`) your model and execute it.\n",
    "\n",
    "But, **BEFORE** that, discuss with your mates:\n",
    "\n",
    "- Why do you think the output layer of the autoencoder uses a Sigmoid activation?\n",
    "- Based on this, decide and justify which cost function is most appropriate for this task.\n",
    "\n",
    "Once you have discussed and agreed on the reasoning above, proceed to complete the skeleton and train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d492d1-2c0a-41f9-b064-ea215a77bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace None to instantiate the autoencoder\n",
    "model = None  \n",
    "\n",
    "# TODO: Replace None with the appropriate Loss function from 'torch.nn'\n",
    "# Hint: we are reconstructing continuous pixel values in [0,1]\n",
    "criterion = None  \n",
    "\n",
    "# TODO: Replace None with Adam optimizer. \n",
    "# Use learning rate of 0.001 and an L2 regularization via weight_decay of 1e-5\n",
    "optimizer = None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b552e-8c1a-4397-8231-23b24ef61368",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.best_model_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def restore_best_weights(self, model):\n",
    "        if self.best_model_state is not None:\n",
    "            model.load_state_dict(self.best_model_state)\n",
    "\n",
    "\n",
    "def train_autoencoder(model, train_loader, val_loader, n_epochs=100, patience=5):\n",
    "    # Initialize the early stopping object\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "    history = {\"train\": [], \"val\": []}\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_cost = 0.0\n",
    "\n",
    "        for X_batch, _ in train_loader:\n",
    "            # --- Implement the standard training steps ---\n",
    "            # TODO: Set gradients equal to zero\n",
    "            outputs = None  # TODO: Forward pass for this batch\n",
    "            cost = None     # TODO: Compute the cost for this batch\n",
    "            # TODO: Backward pass (compute gradients)\n",
    "            # TODO: Update model parameters\n",
    "            train_cost += cost.item() * X_batch.size(0)\n",
    "\n",
    "        train_cost /= len(train_loader.dataset)\n",
    "\n",
    "        # --- Validation phase ---\n",
    "        model.eval()\n",
    "        val_cost = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, _ in val_loader:\n",
    "                outputs = None  # TODO: Forward pass for validation data\n",
    "                cost = None     # TODO: Compute the validation cost\n",
    "                val_cost += cost.item() * X_batch.size(0)\n",
    "\n",
    "        val_cost /= len(val_loader.dataset)\n",
    "\n",
    "        # --- Save metrics ---\n",
    "        history[\"train\"].append(train_cost)\n",
    "        history[\"val\"].append(val_cost)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{n_epochs}]  Train Loss: {train_cost:.5f}  Val Loss: {val_cost:.5f}\")\n",
    "\n",
    "        # --- Early stopping check ---\n",
    "        early_stopping(val_cost, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Stopping early at epoch {epoch+1}\")\n",
    "            early_stopping.restore_best_weights(model)\n",
    "            break\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a90c64-9516-49b9-a65a-76b368d0e142",
   "metadata": {},
   "source": [
    "Once the missing parts have been filled, uncomment the piece of code below and execute it to train your model (it may take a bit to complete the training, which is totally normla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34e426-5072-4ba1-93b7-31983dd450ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, history = train_autoencoder(model, train_loader, val_loader, n_epochs=50, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086b1c2-944f-413e-b0ba-7c55ce7b094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE AS MANY CELLS AS NEEDED FOR THE REST OF THE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d97b6-a983-45fd-8c77-8da76b2032dd",
   "metadata": {},
   "source": [
    "### 3.3 Reconstruct (5 points)\n",
    "\n",
    "Once you have trained the model: \n",
    "\n",
    "1. Visualize several reconstructed digits from the test set.  \n",
    "2. Compare them with the corresponding original input digits. Was the reconstruction good? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff82199-60c8-4e3e-a1c9-ed4bfad276ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE AS MANY CELLS AS NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a375a-2480-4fd4-89a4-6c95b394b313",
   "metadata": {},
   "source": [
    "## 4. Visualize the Learned Representations (15 points)\n",
    "\n",
    "Here you will explore the latent representations learned by your autoencoder.\n",
    "\n",
    "1. Complete `extract_latent_features` to extract the latent (bottleneck) features and their corresponding labels, given a trained model.  \n",
    "   Apply this function to the test set using the provided code. This should give you the transformed test set with the dimensions of the bottleneck (2).\n",
    "2. Plot the results, coloring each point by its corresponding digit label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6b1feb-dee5-42e4-96ce-711b204c91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latent_features(model, dataloader): \n",
    "    model.eval()\n",
    "    latents = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            \n",
    "            encoded = None  # TODO: Apply the encoder part of the model to get the latent features\n",
    "            latents.append(encoded.numpy())\n",
    "            labels.append(y_batch.numpy())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    latents = np.concatenate(latents, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return latents, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f869d-b95a-4554-9165-541e165817f7",
   "metadata": {},
   "source": [
    "Once the missing parts above have been filled, uncomment the piece of code below and execute it to extract the latent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c21d64-9570-4e14-a037-8922270d585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latents_autoencoder, labels = extract_latent_features(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2e954-b804-44f0-a8a8-0d7eaf03595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE AS MANY CELLS AS NEEDED FOR THE REST OF THE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f34eba4-2e2c-41e8-b1ae-6536fe539368",
   "metadata": {},
   "source": [
    "## 5. Compare with PCA (10 points)\n",
    "\n",
    "Here you will compare the latent representations learned by your autoencoder with those obtained using a PCA.\n",
    "\n",
    "1. Apply PCA to the original input data (without using the autoencoder) to reduce the data to the same dimensionality as your bottleneck (2 dimensions). \n",
    "3. Visualize the results. \n",
    "4. Compare the structure of the two plots (Autoencoder vs. PCA) and briefly discuss the differences (if any) you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a2969-3eaf-4194-bfd6-4f5a5efe8011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE AS MANY CELLS AS NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d7abe4-23bf-4045-aa18-f559d4ec7e8a",
   "metadata": {},
   "source": [
    "## 5. Collaboration Reflection (5 points)\n",
    "\n",
    "As a group, briefly reflect on the following (max 1â€“2 short paragraphs):\n",
    "\n",
    "- How did the group dynamics work throughout the assignment?\n",
    "- Were there any major disagreements or diverging approaches?\n",
    "- How did you resolve conflicts or make final modeling decisions?\n",
    "- What did you learn from each other during this project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391935f8-cfbd-4499-80e0-9e987adb7993",
   "metadata": {},
   "source": [
    "YOUR TEXT HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
