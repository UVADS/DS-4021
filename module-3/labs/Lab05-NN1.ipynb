{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1368e02-69f0-463e-9107-c7c37e6e0ac0",
   "metadata": {},
   "source": [
    "# ðŸ§ª LAB: Manual MLPs for Classification and Regression\n",
    "\n",
    "In this lab, you will use `PyTorch` to implement manually a multi-layer perceptron (MLP) for three different tasks: binary classification, multi-class classification and regression. \n",
    "\n",
    "## General instructions to complete in ALL three tasks:\n",
    "\n",
    "1. ***IMPLEMENTATION***:\n",
    "   \n",
    "Implement a separate class for each task:\n",
    "\n",
    "  - `BinaryMLP` for the binary classification task  \n",
    "  - `MultiClassMLP` for the multi-class classification task  \n",
    "  - `RegressionMLP` for the regression task\n",
    "\n",
    "   Each class must include the following methods:\n",
    "\n",
    "  - `__init__` for initializing 1 or 2 hidden layers.\n",
    "  - `forward` to transfer information from the input to the output layer.\n",
    "  - `cost` computing the cost.\n",
    "  - `fit` for training, using autograd and manual updates. **Use stochastic gradient descent to update your weights**. *N.B.* You may probably reuse much of the code we used in this week tutorial already. \n",
    "  - `predict` to convert the information at the output layer into the required output.\n",
    "\n",
    "2. ***DATA PREPARATION***\n",
    "\n",
    "For each task, you will be provided with a toy dataset. For each dataset:\n",
    "\n",
    "  - Split into training and test sets (use an 80/20 split)\n",
    "  - Standardize the features properly, avoiding data leakage\n",
    "  - Convert all data into `PyTorch` Tensors for compatibility\n",
    "\n",
    "3. ***MODEL TRAINING AND EVALUATION***\n",
    "\n",
    "Instantiate the model for each task and train it under different hyperparameter configurations. In each case, record the performance on both the training and test sets using the appropriate metric for the task (accuracy, MSE, etc.). You should explore the following configurations:\n",
    "\n",
    "  - One hidden layer, varying the number of hidden units (use ReLU as their activation function)\n",
    "  - Same number of hidden units across one or two hidden layers (use ReLU as their activation function)\n",
    "  - Repeat the above setups using Tanh activation instead of ReLU\n",
    "\n",
    "Present your results in a compact way (e.g. a summary table, a data frame etc).\n",
    "\n",
    "**NOTE**: When training your model, use a fixed learning rate of your choice (e.g., 0.01 is a reasonable starting point) and a reasonably large number of  epochs (e.g., 100â€“200) based on how training and test performance evolve.\n",
    "\n",
    "4. ***REFLECTION AND DISCUSSION***\n",
    "\n",
    "Reflect on the impact of the different hyperparameter settings:\n",
    "\n",
    "- How does the number of hidden units affect performance?\n",
    "- What changes when using two layers instead of one?\n",
    "- How does the activation function (ReLU vs. Tanh) influence results?\n",
    "\n",
    "Please elaborate your answers.\n",
    "\n",
    "---\n",
    "\n",
    "**Collaboration Note**: This assignment is designed to support collaborative work. We encourage you to divide tasks among group members so that everyone can contribute meaningfully. Many components of the assignment can be approached in parallel or split logically across team members. Good coordination and thoughtful integration of your work will lead to a stronger final result.\n",
    "\n",
    "**Ideally, each group member should be responsible for one of the separate tasks.** BUT, everyone should help each other along the way, both reviewing and refining results and discussion.\n",
    "\n",
    "---\n",
    "\n",
    "In total, this lab assignment will be worth **100 points**.\n",
    "\n",
    "--- \n",
    "**Submission notes**:\n",
    "\n",
    "* Write down all group members' names, or at least the group name (if you have one and you previously provided it), in the first cell of the notebook.\n",
    "\n",
    "* Verify that the notebook runs as expected and that all required outputs are included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb1b88b-ed51-4873-af88-211ff5c2ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME(s) = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8971e94-ed43-45b6-9031-28917379a09d",
   "metadata": {},
   "source": [
    "## 1. Pre-implementation Group Discussion (15 points)\n",
    "\n",
    "Discuss and agree on:\n",
    "\n",
    "- What cost function should be used for each of the below task.\n",
    "- What changes are needed in the output layer for each of these tasks. In particular, consider the number of units and the activation function.\n",
    "- Why it is important to standardize the data before training each model.\n",
    "- How you could detect overfitting when training your models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da4030-2a13-4ce8-ab11-2ae7cbadd360",
   "metadata": {},
   "source": [
    "USE AS MANY MARKDOWN CELLS AS NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5930028c-aa66-43ef-8ab2-357449c50cf1",
   "metadata": {},
   "source": [
    "## 2. Binary Classification (25 points)\n",
    "\n",
    "Use the dataset below to complete points 1 to 4 in the general instructions for this task.\n",
    "\n",
    "Use as many cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ef9eb-7e81-4af9-809d-dc672e4240ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2961c1-dade-42e1-a07a-9118909a81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE AS MANY CELLS AS NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2903c018-71db-40be-b40f-2d9c3814d016",
   "metadata": {},
   "source": [
    "## 2. Multi-Class Classification (25 points)\n",
    "\n",
    "Use the dataset below to complete points 1 to 4 in the general instructions for this task.\n",
    "\n",
    "Use as many cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e6e4c-48df-45c9-9146-4448f3d604e0",
   "metadata": {},
   "source": [
    "---\n",
    "**NOTE**: This will likely be the most challenging exercise. To help you, here are some pointers:\n",
    "\n",
    " - The **output (last) layer** should have as many units as there are classes in your data.  \n",
    "\n",
    " - The **activation function of the output layer must be softmax**, not sigmoid. Softmax ensures that all output values are between 0 and 1 and sum to 1, so they can be interpreted as probabilities across the different classes.  \n",
    "\n",
    " - For a multi-class problem, your target variable `y` should be **one-hot encoded**. For example:  \n",
    "   - Label = 0 â†’ [1, 0, 0]  \n",
    "   - Label = 1 â†’ [0, 1, 0]  \n",
    "   - Label = 2 â†’ [0, 0, 1]  \n",
    "   You can easily achieve this with `OneHotEncoder` from `sklearn.preprocessing`.  \n",
    "\n",
    " - The **predicted class** corresponds to the unit with the highest probability.  \n",
    "   Example:  \n",
    "   - `[0.1, 0.3, 0.6] â†’ class 2`  \n",
    "   - `[0.6, 0.2, 0.2] â†’ class 0`  \n",
    "\n",
    " - For this exercise, you need to **implement the categorical cross-entropy loss** (an extension of binary cross-entropy to multiple classes). It is defined as:  \n",
    "\n",
    "   $$\\sum_{c=1}^{l} y_{o,c}\\,\\log(p_{o,c}),$$\n",
    "\n",
    "   where $l$ is the number of classes, $y_{o,c}$ is the one-hot encoded label for observation $o$, and $p_{o,c}$ is the predicted probability for class $c$ (after applying softmax). The log is the natural logarithm.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3980b88d-e3b0-4ede-bfa4-d854e2842201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_classes=3, \n",
    "                           n_clusters_per_class=1, \n",
    "                           n_features=2, n_informative=2, n_redundant=0, random_state=1234, flip_y=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d05c067-aece-4c59-bf0c-0a994ef7690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE AS MANY CELLS AS NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d530fb-4c1b-40cb-a107-d897e8764550",
   "metadata": {},
   "source": [
    "## 3: Regression Task (25 points)\n",
    "\n",
    "Use the dataset below to complete points 1 to 4 in the general instructions for this task.\n",
    "\n",
    "Use as many cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed90c4d-bf3c-40b9-bd53-0c6d42f88aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=1000, n_features=2, n_informative=2, random_state=1234, noise=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b46422-31ee-4534-bc09-9bda8cee5816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE AS MANY CELLS AS NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8824282-54a8-42da-be16-105be2c403fe",
   "metadata": {},
   "source": [
    "## 4. Discussion (5 points)\n",
    "\n",
    "You created a separate class for each task and likely repeated much of the same code across implementations.\n",
    "\n",
    "Discuss within your group how could you have leveraged inheritance to make your code more reusable and avoid duplication. Provide examples. Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e74115-ce71-45e8-8fae-4ec8c2a45685",
   "metadata": {},
   "source": [
    "YOUR TEXT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5a8a9-e125-411f-9c7e-066eee0999f5",
   "metadata": {},
   "source": [
    "## 5. Collaboration Reflection (5 points)\n",
    "\n",
    "As a group, briefly reflect on the following (max 1â€“2 short paragraphs):\n",
    "\n",
    "- How did the group dynamics work throughout the assignment?\n",
    "- Were there any major disagreements or diverging approaches?\n",
    "- How did you resolve conflicts or make final modeling decisions?\n",
    "- What did you learn from each other during this project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ade16-f0b9-440c-adbe-a135fc88e807",
   "metadata": {},
   "source": [
    "YOUR TEXT HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
